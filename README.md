# classification-challenge
## ğŸ“§ Email Filtering System Improvement ğŸš€

## ğŸŒŸ Background
I've been on a mission to enhance our email filtering system for our beloved Internet Service Provider (ISP) customers! Armed with a dataset containing information about emails, neatly categorized into spam and not spam, I embarked on a thrilling adventure to develop a machine learning model that could accurately detect spam emails and save the day! ğŸ¦¸â€â™‚ï¸ğŸ’¥

## ğŸ“‚ Files
Download the following files to get started:
- [Module 13 Challenge files](https://static.bc-edx.com/ai/ail-v-1-0/m13/challenge/spam-data.csv)

## ğŸš€ Before You Begin
Before diving into this epic journey, here's what I did:
1. Created a new repository named `classification-challenge` to embark on this heroic quest.
2. Cloned the repository to my trusty computer.
3. Added the starter file `spam_detector.ipynb` from the downloaded files to my local Git repository.
4. Pushed the changes to GitHub or GitLab to set sail on this thrilling adventure!

## ğŸ“ Instructions
This exhilarating challenge unfolded as follows:

### ğŸ­ Split the Data into Training and Testing Sets
- I heroically read the data from the provided CSV file into a Pandas DataFrame.
- With anticipation building, I made a bold prediction about which model (logistic regression or random forest) I thought would triumph in this battle against spam!

### ğŸ“Š Scale the Features
- In preparation for the battle ahead, I split the data into training and testing sets.
- Equipped with the mighty StandardScaler, I scaled the features to ensure they were battle-ready!

### ğŸ¤– Creating Models
I crafted two powerful models to tackle the spam menace:

1. **Logistic Regression Model**: Armed with wisdom and cunning, I fitted a logistic regression model to the scaled training data and evaluated its performance using the accuracy score.

2. **Random Forest Model**: Channeling the forces of nature, I forged a random forest classifier model to face the spam onslaught. With bated breath, I gauged its performance using the accuracy score.

### ğŸ‘€ Evaluation
With hearts pounding and excitement in the air, I compared the performance of both models. To my surprise, both models achieved the same accuracy rate! ğŸ˜²ğŸ‰ Despite my initial prediction favoring the random forest model, it seems both contenders stood toe-to-toe in this epic battle against spam!

## ğŸ Conclusion
In the end, this heroic journey taught me valuable lessons about the power of machine learning in combating spam. While my prediction may not have come true, both logistic regression and random forest models proved to be worthy champions in our quest to protect our customers' inboxes! ğŸ›¡ï¸ğŸ“¬ With this newfound knowledge, we're better equipped to improve our email filtering system and safeguard our customers from the perils of spam! ğŸ’ªğŸ”’
